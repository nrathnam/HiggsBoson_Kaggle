# nycdsa-kaggle-project
Machine Learning Kaggle Competition for NYC DSA Project<br>
Higgs Boson Challenge

Due August 21:<br>
  Entire Team --><br> 
    * Perform all single basic algorithms + determine what features to use + document all AMS scores<br>
  Deepak --><br>
    * perform Naive Bayes algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * perform Logistic Regression algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Boosting algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform SVM algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform XGBoost algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
  Nanda --><br>
    * perform XGBoost algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * perform SVM algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Naive Bayes algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Logistic Regression algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Boosting algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
  Venkat --><br>
    * enhance code to extend imputter to include K-Nearest Neighbors<br>
    * perform Boosting algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform SVM algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform XGBoost algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Logistic Regression algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Naive Bayes algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
  Bernard --><br>
    * create AMS reporting sheet for all parameter combinations
    * enhance code to extend sklearn imputter to include "median" and "most_frequent" strategies<br>
    * implement and test feasibility of using deep learning algorithm using Theano/Pylearn2<br>
    * finetune and optimize deep learning hyperparameters
    * if have time, perform Naive Bayes algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Logistic Regression algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform Boosting algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform XGBoost algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>
    * if have time, perform SVM algorithm (varying 6 imputter, 2 scaler, 2 pca, n thresholds)<br>

Team Demibots Members:
<ul>
  <li>Bernard</li>
  <li>Deepak</li>
  <li>Nanda</li>
  <li>Venkat</li>
</ul>
  
Baseline Source code for reference:<br>
http://www.johnwittenauer.net/lessons-learned-from-the-higgs-boson-kaggle-challenge/
